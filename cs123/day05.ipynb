{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 5, Large Language Models in Robotics\n",
    "\n",
    "Think about coding language models - using models to generate code as opposed to other interfaces.\n",
    "\n",
    "#### Current Industry Progress\n",
    "\n",
    "Figure is working with OpenAI for deploying language models in humanoid format. Able to interpret language, slightly long waiting between question and action horizon. \n",
    "\n",
    "Using technologies like: \n",
    "- speech recognition\n",
    "- vision language models\n",
    "- PaLM-SayCan and RT-1\n",
    "\n",
    "#### Diving into Language Modeling\n",
    "\n",
    "Language modeling is the task of predicting which word comes next. The language models on your phone are very small models while Google is a much larger centralized model.\n",
    "\n",
    "1. Scaling Laws: very linear relationship between Pedaflops days and test loss. Read paper to learn more about why. \n",
    "2. Emergent Behavior: larger models aren't linearly better, they are piecewise where they suddenly solve the problem statements as they cross the border of being better than humans.\n",
    "\n",
    "#### Code-As-Policies\n",
    "\n",
    "Here is how it works: \n",
    "THe user prompts a sentence, with predefined APIs at disposal that are organized via function.\n",
    "\n",
    "Code is a logical language and hence it is much easier to use than natural language. With code you can create waiting and longer more computationally expensive sequences.\n",
    "\n",
    "Language models have already read the robotics textbooks.\n",
    "\n",
    "#### Simple Example\n",
    "\n",
    "Give a prompt, with some hints and am example pair. We can use LLM reasoning for fuzzy logic mapping, in the actual instruction generation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
